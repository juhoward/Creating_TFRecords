{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.core._multiarray_umath'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy.core._multiarray_umath'"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<class '_frozen_importlib._ModuleLockManager'> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: <class '_frozen_importlib._ModuleLockManager'> returned a result with an error set"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core._multiarray_umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core._multiarray_umath failed to import"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.umath failed to import"
     ]
    }
   ],
   "source": [
    "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Provides utilities to preprocess images for the Inception networks.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "\n",
    "\n",
    "def apply_with_random_selector(x, func, num_cases):\n",
    "  \"\"\"Computes func(x, sel), with sel sampled from [0...num_cases-1].\n",
    "\n",
    "  Args:\n",
    "    x: input Tensor.\n",
    "    func: Python function to apply.\n",
    "    num_cases: Python int32, number of cases to sample sel from.\n",
    "\n",
    "  Returns:\n",
    "    The result of func(x, sel), where func receives the value of the\n",
    "    selector as a python integer, but sel is sampled dynamically.\n",
    "  \"\"\"\n",
    "  sel = tf.random_uniform([], maxval=num_cases, dtype=tf.int32)\n",
    "  # Pass the real x only to one of the func calls.\n",
    "  return control_flow_ops.merge([\n",
    "      func(control_flow_ops.switch(x, tf.equal(sel, case))[1], case)\n",
    "      for case in range(num_cases)])[0]\n",
    "\n",
    "\n",
    "def distort_color(image, color_ordering=0, fast_mode=True, scope=None):\n",
    "  \"\"\"Distort the color of a Tensor image.\n",
    "\n",
    "  Each color distortion is non-commutative and thus ordering of the color ops\n",
    "  matters. Ideally we would randomly permute the ordering of the color ops.\n",
    "  Rather then adding that level of complication, we select a distinct ordering\n",
    "  of color ops for each preprocessing thread.\n",
    "\n",
    "  Args:\n",
    "    image: 3-D Tensor containing single image in [0, 1].\n",
    "    color_ordering: Python int, a type of distortion (valid values: 0-3).\n",
    "    fast_mode: Avoids slower ops (random_hue and random_contrast)\n",
    "    scope: Optional scope for name_scope.\n",
    "  Returns:\n",
    "    3-D Tensor color-distorted image on range [0, 1]\n",
    "  Raises:\n",
    "    ValueError: if color_ordering not in [0, 3]\n",
    "  \"\"\"\n",
    "  with tf.name_scope(scope, 'distort_color', [image]):\n",
    "    if fast_mode:\n",
    "      if color_ordering == 0:\n",
    "        image = tf.image.random_brightness(image, max_delta=32. / 255.)\n",
    "        image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
    "      else:\n",
    "        image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
    "        image = tf.image.random_brightness(image, max_delta=32. / 255.)\n",
    "    else:\n",
    "      if color_ordering == 0:\n",
    "        image = tf.image.random_brightness(image, max_delta=32. / 255.)\n",
    "        image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
    "        image = tf.image.random_hue(image, max_delta=0.2)\n",
    "        image = tf.image.random_contrast(image, lower=0.5, upper=1.5)\n",
    "      elif color_ordering == 1:\n",
    "        image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
    "        image = tf.image.random_brightness(image, max_delta=32. / 255.)\n",
    "        image = tf.image.random_contrast(image, lower=0.5, upper=1.5)\n",
    "        image = tf.image.random_hue(image, max_delta=0.2)\n",
    "      elif color_ordering == 2:\n",
    "        image = tf.image.random_contrast(image, lower=0.5, upper=1.5)\n",
    "        image = tf.image.random_hue(image, max_delta=0.2)\n",
    "        image = tf.image.random_brightness(image, max_delta=32. / 255.)\n",
    "        image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
    "      elif color_ordering == 3:\n",
    "        image = tf.image.random_hue(image, max_delta=0.2)\n",
    "        image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
    "        image = tf.image.random_contrast(image, lower=0.5, upper=1.5)\n",
    "        image = tf.image.random_brightness(image, max_delta=32. / 255.)\n",
    "      else:\n",
    "        raise ValueError('color_ordering must be in [0, 3]')\n",
    "\n",
    "    # The random_* ops do not necessarily clamp.\n",
    "    return tf.clip_by_value(image, 0.0, 1.0)\n",
    "\n",
    "\n",
    "def distorted_bounding_box_crop(image,\n",
    "                                bbox,\n",
    "                                min_object_covered=0.1,\n",
    "                                aspect_ratio_range=(0.75, 1.33),\n",
    "                                area_range=(0.05, 1.0),\n",
    "                                max_attempts=100,\n",
    "                                scope=None):\n",
    "  \"\"\"Generates cropped_image using a one of the bboxes randomly distorted.\n",
    "\n",
    "  See `tf.image.sample_distorted_bounding_box` for more documentation.\n",
    "\n",
    "  Args:\n",
    "    image: 3-D Tensor of image (it will be converted to floats in [0, 1]).\n",
    "    bbox: 3-D float Tensor of bounding boxes arranged [1, num_boxes, coords]\n",
    "      where each coordinate is [0, 1) and the coordinates are arranged\n",
    "      as [ymin, xmin, ymax, xmax]. If num_boxes is 0 then it would use the whole\n",
    "      image.\n",
    "    min_object_covered: An optional `float`. Defaults to `0.1`. The cropped\n",
    "      area of the image must contain at least this fraction of any bounding box\n",
    "      supplied.\n",
    "    aspect_ratio_range: An optional list of `floats`. The cropped area of the\n",
    "      image must have an aspect ratio = width / height within this range.\n",
    "    area_range: An optional list of `floats`. The cropped area of the image\n",
    "      must contain a fraction of the supplied image within in this range.\n",
    "    max_attempts: An optional `int`. Number of attempts at generating a cropped\n",
    "      region of the image of the specified constraints. After `max_attempts`\n",
    "      failures, return the entire image.\n",
    "    scope: Optional scope for name_scope.\n",
    "  Returns:\n",
    "    A tuple, a 3-D Tensor cropped_image and the distorted bbox\n",
    "  \"\"\"\n",
    "  with tf.name_scope(scope, 'distorted_bounding_box_crop', [image, bbox]):\n",
    "    # Each bounding box has shape [1, num_boxes, box coords] and\n",
    "    # the coordinates are ordered [ymin, xmin, ymax, xmax].\n",
    "\n",
    "    # A large fraction of image datasets contain a human-annotated bounding\n",
    "    # box delineating the region of the image containing the object of interest.\n",
    "    # We choose to create a new bounding box for the object which is a randomly\n",
    "    # distorted version of the human-annotated bounding box that obeys an\n",
    "    # allowed range of aspect ratios, sizes and overlap with the human-annotated\n",
    "    # bounding box. If no box is supplied, then we assume the bounding box is\n",
    "    # the entire image.\n",
    "    sample_distorted_bounding_box = tf.image.sample_distorted_bounding_box(\n",
    "        tf.shape(image),\n",
    "        bounding_boxes=bbox,\n",
    "        min_object_covered=min_object_covered,\n",
    "        aspect_ratio_range=aspect_ratio_range,\n",
    "        area_range=area_range,\n",
    "        max_attempts=max_attempts,\n",
    "        use_image_if_no_bounding_boxes=True)\n",
    "    bbox_begin, bbox_size, distort_bbox = sample_distorted_bounding_box\n",
    "\n",
    "    # Crop the image to the specified bounding box.\n",
    "    cropped_image = tf.slice(image, bbox_begin, bbox_size)\n",
    "    return cropped_image, distort_bbox\n",
    "\n",
    "\n",
    "def preprocess_for_train(image,\n",
    "                         height,\n",
    "                         width,\n",
    "                         bbox,\n",
    "                         fast_mode=True,\n",
    "                         scope=None,\n",
    "                         add_image_summaries=True,\n",
    "                         random_crop=True):\n",
    "  \"\"\"Distort one image for training a network.\n",
    "\n",
    "  Distorting images provides a useful technique for augmenting the data\n",
    "  set during training in order to make the network invariant to aspects\n",
    "  of the image that do not effect the label.\n",
    "\n",
    "  Additionally it would create image_summaries to display the different\n",
    "  transformations applied to the image.\n",
    "\n",
    "  Args:\n",
    "    image: 3-D Tensor of image. If dtype is tf.float32 then the range should be\n",
    "      [0, 1], otherwise it would converted to tf.float32 assuming that the range\n",
    "      is [0, MAX], where MAX is largest positive representable number for\n",
    "      int(8/16/32) data type (see `tf.image.convert_image_dtype` for details).\n",
    "    height: integer\n",
    "    width: integer\n",
    "    bbox: 3-D float Tensor of bounding boxes arranged [1, num_boxes, coords]\n",
    "      where each coordinate is [0, 1) and the coordinates are arranged\n",
    "      as [ymin, xmin, ymax, xmax].\n",
    "    fast_mode: Optional boolean, if True avoids slower transformations (i.e.\n",
    "      bi-cubic resizing, random_hue or random_contrast).\n",
    "    scope: Optional scope for name_scope.\n",
    "    add_image_summaries: Enable image summaries.\n",
    "    random_crop: Enable random cropping of images during preprocessing for\n",
    "      training.\n",
    "  Returns:\n",
    "    3-D float Tensor of distorted image used for training with range [-1, 1].\n",
    "  \"\"\"\n",
    "  with tf.name_scope(scope, 'distort_image', [image, height, width, bbox]):\n",
    "    if bbox is None:\n",
    "      bbox = tf.constant([0.0, 0.0, 1.0, 1.0],\n",
    "                         dtype=tf.float32,\n",
    "                         shape=[1, 1, 4])\n",
    "    if image.dtype != tf.float32:\n",
    "      image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    # Each bounding box has shape [1, num_boxes, box coords] and\n",
    "    # the coordinates are ordered [ymin, xmin, ymax, xmax].\n",
    "    image_with_box = tf.image.draw_bounding_boxes(tf.expand_dims(image, 0),\n",
    "                                                  bbox)\n",
    "    if add_image_summaries:\n",
    "      tf.summary.image('image_with_bounding_boxes', image_with_box)\n",
    "\n",
    "    if not random_crop:\n",
    "      distorted_image = image\n",
    "    else:\n",
    "      distorted_image, distorted_bbox = distorted_bounding_box_crop(image, bbox)\n",
    "      # Restore the shape since the dynamic slice based upon the bbox_size loses\n",
    "      # the third dimension.\n",
    "      distorted_image.set_shape([None, None, 3])\n",
    "      image_with_distorted_box = tf.image.draw_bounding_boxes(\n",
    "          tf.expand_dims(image, 0), distorted_bbox)\n",
    "      if add_image_summaries:\n",
    "        tf.summary.image('images_with_distorted_bounding_box',\n",
    "                         image_with_distorted_box)\n",
    "\n",
    "    # This resizing operation may distort the images because the aspect\n",
    "    # ratio is not respected. We select a resize method in a round robin\n",
    "    # fashion based on the thread number.\n",
    "    # Note that ResizeMethod contains 4 enumerated resizing methods.\n",
    "\n",
    "    # We select only 1 case for fast_mode bilinear.\n",
    "    num_resize_cases = 1 if fast_mode else 4\n",
    "    distorted_image = apply_with_random_selector(\n",
    "        distorted_image,\n",
    "        lambda x, method: tf.image.resize_images(x, [height, width], method),\n",
    "        num_cases=num_resize_cases)\n",
    "\n",
    "    if add_image_summaries:\n",
    "      tf.summary.image(('cropped_' if random_crop else '') + 'resized_image',\n",
    "                       tf.expand_dims(distorted_image, 0))\n",
    "\n",
    "    # Randomly flip the image horizontally.\n",
    "    distorted_image = tf.image.random_flip_left_right(distorted_image)\n",
    "\n",
    "    # Randomly distort the colors. There are 1 or 4 ways to do it.\n",
    "    num_distort_cases = 1 if fast_mode else 4\n",
    "    distorted_image = apply_with_random_selector(\n",
    "        distorted_image,\n",
    "        lambda x, ordering: distort_color(x, ordering, fast_mode),\n",
    "        num_cases=num_distort_cases)\n",
    "\n",
    "    if add_image_summaries:\n",
    "      tf.summary.image('final_distorted_image',\n",
    "                       tf.expand_dims(distorted_image, 0))\n",
    "    distorted_image = tf.subtract(distorted_image, 0.5)\n",
    "    distorted_image = tf.multiply(distorted_image, 2.0)\n",
    "    return distorted_image\n",
    "\n",
    "\n",
    "def preprocess_for_eval(image,\n",
    "                        height,\n",
    "                        width,\n",
    "                        central_fraction=0.875,\n",
    "                        scope=None,\n",
    "                        central_crop=True):\n",
    "  \"\"\"Prepare one image for evaluation.\n",
    "\n",
    "  If height and width are specified it would output an image with that size by\n",
    "  applying resize_bilinear.\n",
    "\n",
    "  If central_fraction is specified it would crop the central fraction of the\n",
    "  input image.\n",
    "\n",
    "  Args:\n",
    "    image: 3-D Tensor of image. If dtype is tf.float32 then the range should be\n",
    "      [0, 1], otherwise it would converted to tf.float32 assuming that the range\n",
    "      is [0, MAX], where MAX is largest positive representable number for\n",
    "      int(8/16/32) data type (see `tf.image.convert_image_dtype` for details).\n",
    "    height: integer\n",
    "    width: integer\n",
    "    central_fraction: Optional Float, fraction of the image to crop.\n",
    "    scope: Optional scope for name_scope.\n",
    "    central_crop: Enable central cropping of images during preprocessing for\n",
    "      evaluation.\n",
    "  Returns:\n",
    "    3-D float Tensor of prepared image.\n",
    "  \"\"\"\n",
    "  with tf.name_scope(scope, 'eval_image', [image, height, width]):\n",
    "    if image.dtype != tf.float32:\n",
    "      image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    # Crop the central region of the image with an area containing 87.5% of\n",
    "    # the original image.\n",
    "    if central_crop and central_fraction:\n",
    "      image = tf.image.central_crop(image, central_fraction=central_fraction)\n",
    "\n",
    "    if height and width:\n",
    "      # Resize the image to the specified height and width.\n",
    "      image = tf.expand_dims(image, 0)\n",
    "      image = tf.image.resize_bilinear(image, [height, width],\n",
    "                                       align_corners=False)\n",
    "      image = tf.squeeze(image, [0])\n",
    "    image = tf.subtract(image, 0.5)\n",
    "    image = tf.multiply(image, 2.0)\n",
    "    return image\n",
    "\n",
    "\n",
    "def preprocess_image(image,\n",
    "                     height,\n",
    "                     width,\n",
    "                     is_training=False,\n",
    "                     bbox=None,\n",
    "                     fast_mode=True,\n",
    "                     add_image_summaries=True,\n",
    "                     crop_image=True):\n",
    "  \"\"\"Pre-process one image for training or evaluation.\n",
    "\n",
    "  Args:\n",
    "    image: 3-D Tensor [height, width, channels] with the image. If dtype is\n",
    "      tf.float32 then the range should be [0, 1], otherwise it would converted\n",
    "      to tf.float32 assuming that the range is [0, MAX], where MAX is largest\n",
    "      positive representable number for int(8/16/32) data type (see\n",
    "      `tf.image.convert_image_dtype` for details).\n",
    "    height: integer, image expected height.\n",
    "    width: integer, image expected width.\n",
    "    is_training: Boolean. If true it would transform an image for train,\n",
    "      otherwise it would transform it for evaluation.\n",
    "    bbox: 3-D float Tensor of bounding boxes arranged [1, num_boxes, coords]\n",
    "      where each coordinate is [0, 1) and the coordinates are arranged as\n",
    "      [ymin, xmin, ymax, xmax].\n",
    "    fast_mode: Optional boolean, if True avoids slower transformations.\n",
    "    add_image_summaries: Enable image summaries.\n",
    "    crop_image: Whether to enable cropping of images during preprocessing for\n",
    "      both training and evaluation.\n",
    "\n",
    "  Returns:\n",
    "    3-D float Tensor containing an appropriately scaled image\n",
    "\n",
    "  Raises:\n",
    "    ValueError: if user does not provide bounding box\n",
    "  \"\"\"\n",
    "  if is_training:\n",
    "    return preprocess_for_train(\n",
    "        image,\n",
    "        height,\n",
    "        width,\n",
    "        bbox,\n",
    "        fast_mode,\n",
    "        add_image_summaries=add_image_summaries,\n",
    "        random_crop=crop_image)\n",
    "  else:\n",
    "    return preprocess_for_eval(image, height, width, central_crop=crop_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
